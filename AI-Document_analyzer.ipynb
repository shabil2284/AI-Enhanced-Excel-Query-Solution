{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c01a657-c713-43f4-914c-69d66f15bd8d",
   "metadata": {},
   "source": [
    "# Install Python Dependencies from `require.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0d5769-664f-4f72-9fac-de22a950e773",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 7)) (6.28.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 8)) (75.1.0)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 9)) (0.44.0)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 10)) (3.1.5)\n",
      "Collecting cython (from -r require.txt (line 11))\n",
      "  Using cached cython-3.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pymupdf in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 14)) (1.25.5)\n",
      "Requirement already satisfied: pdf2image in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 15)) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 16)) (20231228)\n",
      "Collecting tabula-py (from -r require.txt (line 18))\n",
      "  Using cached tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting ghostscript (from -r require.txt (line 19))\n",
      "  Using cached ghostscript-0.7-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: pdfplumber in /opt/anaconda3/lib/python3.12/site-packages (from -r require.txt (line 20)) (0.11.5)\n",
      "Collecting tensorflow (from -r require.txt (line 23))\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r \"require.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb2ff4-0b93-414a-b0c4-27a71cc93752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentenceTransformer Model (`all-MiniLM-L12-v2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1863f602-8a39-4249-919c-72f0a47ca7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SentenceTransformer imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L12-v2\")\n",
    "print(\"‚úÖ SentenceTransformer imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8712cb-9077-420b-b83d-7f8697f69e89",
   "metadata": {},
   "source": [
    "# Locate a Specific File by Name in a Folder and Subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700feff1-0f45-4226-af67-9ab86199d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File found at: /Users/shabil/Desktop/file_example_XLS_5000 (2).xls\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = \"file_example_XLS_5000 (2).xls\"  # Change to your actual file name\n",
    "search_path = \"/Users/shabil/Desktop\"  # Change to your search directory\n",
    "\n",
    "for root, dirs, files in os.walk(search_path):\n",
    "    if filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        print(\"‚úÖ File found at:\", file_path)\n",
    "        break\n",
    "else:\n",
    "    print(\"‚ùå File not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48d47c-3185-46cb-8ee9-2cf8136149e6",
   "metadata": {},
   "source": [
    "# Function to Load Excel Files (.xls or .xlsx) and Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a39305-968c-4c36-a24f-990ff678060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded file!\n",
      "üìå Columns detected: ['Unnamed: 0', 'First Name', 'Last Name', 'Gender', 'Country', 'Age', 'Date', 'Id']\n",
      "   Unnamed: 0 First Name  Last Name  Gender        Country  Age        Date    Id\n",
      "0           1      Dulce      Abril  Female  United States   32  15/10/2017  1562\n",
      "1           2       Mara  Hashimoto  Female  Great Britain   25  16/08/2016  1582\n",
      "2           3     Philip       Gent    Male         France   36  21/05/2015  2587\n",
      "3           4   Kathleen     Hanner  Female  United States   25  15/10/2017  3549\n",
      "4           5    Nereida    Magwood  Female  United States   58  16/08/2016  2468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel File\n",
    "def load_excel(file_path):\n",
    "    try:\n",
    "        # Choose correct engine based on file type\n",
    "        if file_path.endswith(\".xls\"):\n",
    "            df = pd.read_excel(file_path, engine=\"xlrd\")  # For .xls\n",
    "        else:\n",
    "            df = pd.read_excel(file_path, engine=\"openpyxl\")  # For .xlsx\n",
    "        \n",
    "        print(\"‚úÖ Successfully loaded file!\")\n",
    "        print(\"üìå Columns detected:\", df.columns.tolist())  # Show column names\n",
    "\n",
    "        # Display all rows and columns\n",
    "        pd.set_option(\"display.max_rows\", None)  # Show all rows\n",
    "        pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "        pd.set_option(\"display.expand_frame_repr\", False)  # Prevent line breaks\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error loading file:\", e)\n",
    "        return None\n",
    "\n",
    "# Example Usage:\n",
    "file_path = \"/Users/shabil/Desktop/file_example_XLS_5000 (2).xls\"  # Ensure correct path\n",
    "df = load_excel(file_path)\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    print(df.head())  # Show first few rows for verification\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not load the Excel file. Check the error above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820ad5c2-c6d9-414d-9a5c-3fb599cb8d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ† Cleaning Data...\n",
      "Data cleaning complete!\n",
      "Data shape after cleaning: (5000, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/3sj3r3sx07b3fgdmcbmgjcy00000gn/T/ipykernel_14293/4122198992.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Clean Data\n",
    "def clean_data(df):\n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ö†Ô∏è DataFrame is empty. Skipping cleaning.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"üõ† Cleaning Data...\")\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove rows with all NaN values\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    # Trim whitespace from string columns\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # Fill missing values (example: replacing NaN with 'Unknown' in object columns)\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    print(\"Data cleaning complete!\")\n",
    "    print(\"Data shape after cleaning:\", df.shape)  \n",
    "    return df\n",
    "\n",
    "# Apply cleaning\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c0a98-2929-4ab7-b05e-c7681dd54a08",
   "metadata": {},
   "source": [
    "# Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f122604-2df7-4012-a267-ec80101f1c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fdabc93-d6d9-44d2-ab99-57adc052d452",
   "metadata": {},
   "source": [
    "# Step 1: Initialize Dependencies and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baed4f6-289a-4198-af06-08ea31b8e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "# Simplified approach without complex LangChain chains\n",
    "class SimplifiedLangChainChatbot:\n",
    "    def __init__(self):\n",
    "        # Initialize ChromaDB\n",
    "        self.client = chromadb.PersistentClient(path=\"./vector_db\")  \n",
    "        self.collection = self.client.get_or_create_collection(\"company_info\")\n",
    "        \n",
    "        # Initialize SentenceTransformer\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        # Simple conversation memory\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a313e5d-aaf0-47f9-bcd1-d75a6cee1222",
   "metadata": {},
   "source": [
    "#  Step2:Vector Search and User Guidance Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3614e83b-bcff-4497-b6ca-8090a3cc7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def search_vector_db(self, query, top_k=50):\n",
    "        \"\"\"Search the vector database\"\"\"\n",
    "        query_embedding = self.model.encode(query).tolist()\n",
    "        results = self.collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "        if results and \"documents\" in results and results[\"documents\"]:\n",
    "            retrieved_texts = [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "            return list(set(retrieved_texts))  # Ensure unique entries only\n",
    "        return []\n",
    "    \n",
    "    def get_current_datetime(self):\n",
    "        \"\"\"Get current date and time\"\"\"\n",
    "        now = datetime.now()\n",
    "        return now.strftime(\"%A, %B %d, %Y at %I:%M %p\")\n",
    "    \n",
    "    def suggest_questions(self):\n",
    "        \"\"\"Suggest example questions\"\"\"\n",
    "        examples = [\n",
    "            \"What is the total revenue for the last quarter?\",\n",
    "            \"How many employees are working in the IT department?\",\n",
    "            \"Can you list the top 5 performing products?\",\n",
    "            \"What was the highest sale recorded this year?\",\n",
    "            \"Provide a summary of all available data.\"\n",
    "        ]\n",
    "        return \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e2dc0-136c-44fd-97c5-874ccc4d6d7b",
   "metadata": {},
   "source": [
    "# Step 3: Handle Queries with Context and AI Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7db3fef-a56b-4327-b416-17ab432eaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build_context_with_history(self, current_query, retrieved_data):\n",
    "        \"\"\"Build context including conversation history\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        # Add conversation history (last 3 exchanges)\n",
    "        if self.conversation_history:\n",
    "            context_parts.append(\"### Recent Conversation:\")\n",
    "            for i, (q, a) in enumerate(self.conversation_history[-3:]):\n",
    "                context_parts.append(f\"Previous Q{i+1}: {q}\")\n",
    "                context_parts.append(f\"Previous A{i+1}: {a[:200]}...\")  # Truncate long answers\n",
    "        \n",
    "        # Add current retrieved data\n",
    "        if retrieved_data:\n",
    "            context_parts.append(\"### Current Dataset Context:\")\n",
    "            context_parts.extend(retrieved_data)\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def chat_with_ollama(self, query, retrieved_data, date_info):\n",
    "        \"\"\"Enhanced chat with Ollama including conversation context\"\"\"\n",
    "        \n",
    "        if not retrieved_data:\n",
    "            example_questions = self.suggest_questions()\n",
    "            return f\"I couldn't find any relevant data. Please ask only about the provided dataset.\\n\\nYou can ask questions for example:\\n{example_questions}\"\n",
    "        \n",
    "        # Build context with conversation history\n",
    "        full_context = self.build_context_with_history(query, retrieved_data)\n",
    "        \n",
    "        full_prompt = f\"\"\"You are an AI assistant analyzing a dataset with conversation memory.\n",
    "Answer **only** using the data provided. If a user asks about something outside the dataset, tell them to ask about the provided information.\n",
    "\n",
    "{date_info}\n",
    "\n",
    "{full_context}\n",
    "\n",
    "### Current User Query:\n",
    "{query}\n",
    "\n",
    "**Instructions:**\n",
    "- Consider the conversation history when answering\n",
    "- Do **not summarize excessively**‚Äîinclude all relevant information\n",
    "- If the user asks for a list, **format the response properly**\n",
    "- If the answer is too long, split it into **clear sections**\n",
    "- If you are unsure, politely say: \"I can only answer questions related to the dataset provided.\"\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=\"mistral\",  \n",
    "                messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "                options={\"num_predict\": 16384}\n",
    "            )\n",
    "            answer = response[\"message\"][\"content\"]\n",
    "            \n",
    "            # Store in conversation history\n",
    "            self.conversation_history.append((query, answer))\n",
    "            \n",
    "            # Keep only last 5 conversations to manage memory\n",
    "            if len(self.conversation_history) > 5:\n",
    "                self.conversation_history = self.conversation_history[-5:]\n",
    "            \n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error communicating with Ollama: {str(e)}\"\n",
    "    \n",
    "    def process_query(self, query: str) -> str:\n",
    "        \"\"\"Process a user query\"\"\"\n",
    "        current_datetime = self.get_current_datetime()\n",
    "        date_message = f\"Today's date and time is {current_datetime}.\"\n",
    "        \n",
    "        # Special handling for listing people\n",
    "        if \"list all the people\" in query.lower():\n",
    "            retrieved_data = self.search_vector_db(query, top_k=50)\n",
    "            if retrieved_data:\n",
    "                formatted_people = \"\\n\".join([f\"- {data}\" for data in retrieved_data])\n",
    "                answer = f\"Here are the unique people found in the dataset:\\n\\n{formatted_people}\"\n",
    "                self.conversation_history.append((query, answer))\n",
    "                return answer\n",
    "            else:\n",
    "                return \"I couldn't find any relevant data about people in the dataset.\"\n",
    "        \n",
    "        # Regular query processing\n",
    "        retrieved_data = self.search_vector_db(query)\n",
    "        return self.chat_with_ollama(query, retrieved_data, date_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78881e18-a5ee-4e24-b611-f61119f9633e",
   "metadata": {},
   "source": [
    "# Step 3: Maintain Dataset and Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc95da3-8417-4c12-a3d6-63ce1dbb0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def add_documents_to_vector_store(self, texts: List[str], metadatas: Optional[List[dict]] = None):\n",
    "        \"\"\"Add documents to the vector store\"\"\"\n",
    "        embeddings = [self.model.encode(text).tolist() for text in texts]\n",
    "        ids = [f\"doc_{i}_{datetime.now().timestamp()}\" for i in range(len(texts))]\n",
    "        \n",
    "        self.collection.add(\n",
    "            documents=texts,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=metadatas or [{\"source\": f\"added_doc_{i}\"} for i in range(len(texts))],\n",
    "            ids=ids\n",
    "        )\n",
    "        print(f\"‚úÖ Added {len(texts)} documents to vector store\")\n",
    "    \n",
    "    def clear_conversation_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"üßπ Conversation history cleared!\")\n",
    "    \n",
    "    def show_conversation_history(self):\n",
    "        \"\"\"Show recent conversation history\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            print(\"No conversation history available.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\nüìú Recent Conversation History:\")\n",
    "        for i, (q, a) in enumerate(self.conversation_history[-3:], 1):\n",
    "            print(f\"\\n{i}. Q: {q}\")\n",
    "            print(f\"   A: {a[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ea312-a287-4376-8d40-884b53eb1dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d35741-52c9-4d88-82f7-e2052c9bd861",
   "metadata": {},
   "source": [
    "# Step4: Main Interactive Chat Loop for User Queries and Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15946fd5-406a-4a4c-8a93-de54cf4a90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def chat_loop(self):\n",
    "        \"\"\"Main chat loop\"\"\"\n",
    "        print(\"ü§ñ Enhanced LangChain-Style Chatbot initialized!\")\n",
    "        print(\"You can now ask questions about your dataset.\")\n",
    "        print(\"\\nCommands:\")\n",
    "        print(\"- 'exit' to quit\")\n",
    "        print(\"- 'clear' to clear conversation history\")\n",
    "        print(\"- 'history' to show recent conversation\")\n",
    "        print(\"- 'help' for example questions\")\n",
    "        \n",
    "        while True:\n",
    "            user_query = input(\"\\nAsk about any details: \").strip()\n",
    "            \n",
    "            if not user_query:\n",
    "                continue\n",
    "                \n",
    "            if user_query.lower() == \"exit\":\n",
    "                print(\"Goodbye! üëã\")\n",
    "                break\n",
    "            elif user_query.lower() == \"clear\":\n",
    "                self.clear_conversation_history()\n",
    "                continue\n",
    "            elif user_query.lower() == \"history\":\n",
    "                self.show_conversation_history()\n",
    "                continue\n",
    "            elif user_query.lower() == \"help\":\n",
    "                example_questions = self.suggest_questions()\n",
    "                print(f\"\\nHere are some example questions you can ask:\\n{example_questions}\")\n",
    "                continue\n",
    "            \n",
    "            # Process the query\n",
    "            print(\"\\nü§ñ Thinking...\")\n",
    "            response = self.process_query(user_query)\n",
    "            print(f\"\\nü§ñ Chat:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e30494-96e0-4cbe-967e-eca504469c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738dce15-11f4-4f8a-b846-11ef04baaedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41ed6c-c943-4d9f-bbe9-99c15ee672df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd377cc-6eed-4651-a404-f2e608059d84",
   "metadata": {},
   "source": [
    "# Step5:Main Function: Initialize and Start Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9a8b2e-2a51-40fa-bc09-aed9afd9cae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SimplifiedLangChainChatbot' object has no attribute 'chat_loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     chatbot\u001b[38;5;241m.\u001b[39mchat_loop()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Initialize the chatbot\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     chatbot \u001b[38;5;241m=\u001b[39m SimplifiedLangChainChatbot()\n\u001b[0;32m----> 5\u001b[0m     chatbot\u001b[38;5;241m.\u001b[39mchat_loop()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SimplifiedLangChainChatbot' object has no attribute 'chat_loop'"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "def main():\n",
    "    # Initialize the chatbot\n",
    "    chatbot = SimplifiedLangChainChatbot()\n",
    "    chatbot.chat_loop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
